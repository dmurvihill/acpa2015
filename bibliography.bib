@misc{bernstein2005cache,
  title={Cache-timing attacks on AES},
  author={Bernstein, Daniel J},
  year={2005}
}

@incollection{bonneau2006cache,
  title={Cache-collision timing attacks against AES},
  author={Bonneau, Joseph and Mironov, Ilya},
  booktitle={Cryptographic Hardware and Embedded Systems-CHES 2006},
  pages={201--215},
  year={2006},
  publisher={Springer}
}

@inproceedings{gullasch2011cache,
  title={Cache games--{Bringing} access-based cache attacks on {AES} to practice},
  author={Gullasch, David and Bangerter, Endre and Krenn, Stephan},
  booktitle={Security and Privacy (SP), 2011 IEEE Symposium on},
  pages={490--505},
  year={2011},
  organization={IEEE},
  annote={
    \setlength{\parskip}{1.5ex}
    Describes an access-driven full-key recovery cache attack on AES.
    The authors claim it is the first attack to work in Ostvik's~\cite{osvik2006cache} \textit{asynchronous}
      model --- the online attack phase requires only co-location on the same CPU core and shared memory, but no
      explicit interactions.
    It also requires no knowledge of the plaintexts or even the ciphertexts, works against compressed-table
      implementations for the first time, and can recover a full AES-128 key after observing just \num{100}~encryptions
      (\num{2.8}~seconds) and a three-minute offline analysis phase.
    \par
    The cryptanalysis uses a novel attack against the Completely Fair Scheduler (CFS), the scheduler used in the Linux
      kernel, ``to observe (on average) every single memory access of the victim process.''
    The CFS attack runs one hundred threads which spend most of their time in the ``blocked'' state, ensuring that
      their total execution time is low and CFS will prioritize them over the victim process when they are unblocked.
    When an attack thread wakes, it reads the memory accesses of the process that ran just before, then sets a timer to
      wake up the next attack thread, after a short delay, then yields the CPU so that the victim process can run.
    The goal is to unblock the next attack thread after exactly one memory access by the victim process. In the
      authors' case, this was about \num{1500}~CPU cycles.
    They computed the required delay empirically, using OS-specific techniques; they also used two artificial neural
      networks, trained on about \num{168000}~encryptions using the same OS, hardware, and encryption library as the
      target, to design noise-reduction algorithms for this step to filter out irrelevant memory accesses.
    \par
    Because of the reliance on specific operating system properties for accurate measurement, the attack is highly
      dependent on the target platform~--- the authors mentioned that any deviation from their Linux kernel running
      OpenSSL~0.9.8n on a single-core x86 CPU required significant adjustment.
    OpenSSL~1.0 makes the attack significantly more difficult.
    They mentioned that even ``minor updates to the operating system'' required the attack to be re-tuned.
    \par
    They suggest that porting the attack to target other operating systems would be difficult, especially against
      proprietary operating systems where the attacker would have to reverse-engineer the scheduler.
    Multi-core CPUs also present a challenge, because the cache access attack depends on the victim process being
      preempted while the spy process is running.
    They suggest that the spy could run on multiple cores, and also try to influence the target to run on certain cores
      by exploiting the task scheduler or making specific system calls.
  }
}

@incollection{irazoqui2014wait,
  title={Wait a minute! A fast, {Cross-VM} attack on {AES}},
  author={Irazoqui, Gorka and Inci, Mehmet Sinan and Eisenbarth, Thomas and Sunar, Berk},
  booktitle={Research in Attacks, Intrusions and Defenses},
  pages={299--319},
  year={2014},
  publisher={Springer},
  annote={
    Demonstrates a practical, fast, and realistic full key recovery against AES across virtual machines.
    The attack is based on the \name{Flush+Reload} attack from Gullasch \latin{et al.} \cite{gullasch2011cache}.
    It works against any T-table based cipher implementation, but only when the VMs are using same sort of memory
      sharing mechanism such as VMware TPS.
    Key recovery takes about one minute (400,000~encryptions) in a realistic cross-VM setting.
    \par
    The attack assumes the use of the co-location technique invented by Ristenpart \latin{et al.} to move to the same
      host as the target VM.
    Once co-located, it uses a \name{Flush+Reload} attack, which works in three steps:
    \begin{enumerate}
      \item \emph{flush} the cache lines which the attacker wants to observe
      \item wait for the target to run the interesting fragment of code such as an encryption
      \item \emph{reload} the same memory lines; the cache lines which the target accessed will be cached, and will
        load faster for the attacker.
    \end{enumerate}
    \par
    Specifically, the \name{Flush+Reload} targets accesses of the T table used in the final round of encryption.
    By observing accesses of the final T table, the attacker is able to observe the final-round state of the algorithm
      and can use this information, together with the ciphertext, to recover the key.
    \par
    The attack takes advantage of two isolation leaks which the target system relies on to improve performance: The
      fact that identical memory pages (such as libraries) are usually shared between virtual machines, and the fact
      that L3 cache is usually shared between cores.
    The first property allows the attacker to observe the target's memory access across VMs, the second allows the
      attacker to observe memory access across CPU cores.
    As a result, the attacker and target need only be sharing the same physical host.
    \par
    Irazoqui \latin{et al.} tested their implementation on a consumer VM running VMware ESXi. The target was an
      encryption server which accepted plaintexts and responded with ciphertexts.
    The attack program ran on a different VM on a different core of the same host and was able to send encryption
      requests to the target.
    It recovered the full key in 400,000 encryptions --- less than a minute.
    They also tested their approach and observed even better results in some non cross-VM situations.
  }
}

@article{irazoquistealing,
  title={Stealing Information From Large Caches via Huge Pages},
  author={Irazoqui, Gorka and Eisenbarth, Thomas and Sunar, Berk}
}

@inproceedings{varadarajan2014scheduler,
  title={Scheduler-based defenses against cross-vm side-channels},
  author={Varadarajan, Venkatanathan and Ristenpart, Thomas and Swift, Michael},
  booktitle={Usenix Security},
  year={2014}
}

@article{yarom2013flush+,
  title={Flush+ Reload: a High Resolution, Low Noise, L3 Cache Side-Channel Attack.},
  author={Yarom, Yuval and Falkner, Katrina E},
  journal={IACR Cryptology ePrint Archive},
  volume={2013},
  pages={448},
  year={2013}
}

@inproceedings{zhang2014cross,
  title={Cross-Tenant Side-Channel Attacks in PaaS Clouds},
  author={Zhang, Yinqian and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
  pages={990--1003},
  year={2014},
  organization={ACM}
}

